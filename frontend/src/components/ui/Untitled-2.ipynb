{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2490503976.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    import React from 'react';\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import React from 'react';\n",
    "import Highcharts from 'highcharts/highstock';\n",
    "import HighchartsReact from 'highcharts-react-official';\n",
    "\n",
    "const StockChart = ({ data }) => {\n",
    "  const options = {\n",
    "    title: {\n",
    "      text: 'Stock Price'\n",
    "    },\n",
    "    xAxis: {\n",
    "      type: 'datetime'\n",
    "    },\n",
    "    yAxis: {\n",
    "      title: {\n",
    "        text: 'Price'\n",
    "      }\n",
    "    },\n",
    "    series: [{\n",
    "      name: 'Stock Price',\n",
    "      data: data,\n",
    "      tooltip: {\n",
    "        valueDecimals: 2\n",
    "      }\n",
    "    }]\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <HighchartsReact\n",
    "      highcharts={Highcharts}\n",
    "      constructorType={'stockChart'}\n",
    "      options={options}\n",
    "    />\n",
    "  );\n",
    "};\n",
    "\n",
    "export default StockChart;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if (isChatActive) {\n",
    "    return (\n",
    "      <div className={styles.chatPage}>\n",
    "        <div className={styles.chatHeader}>\n",
    "          <div className={styles.chatHeaderTitle}>\n",
    "            <div className={styles.iconWrapper}>\n",
    "              <FluentIcons.Sparkle24Filled />\n",
    "            </div>\n",
    "            <Text className={styles.chatHeaderText}>{userConfig.buttons[0].label}</Text>\n",
    "          </div>\n",
    "          <Text className={styles.chatHeaderDescription}>{userConfig.buttons[0].description}</Text>\n",
    "        </div>\n",
    "        <div className={styles.chatMessages}>\n",
    "          {chatMessages.map((message, index) => (\n",
    "            <React.Fragment key={index}>\n",
    "              <div\n",
    "                className={`${styles.chatMessage} ${\n",
    "                  message.role === \"user\" ? styles.userMessage : styles.assistantMessage\n",
    "                }`}\n",
    "              >\n",
    "                {message.role === \"user\" ? (\n",
    "                  message.content\n",
    "                ) : (\n",
    "                  <div dangerouslySetInnerHTML={{ __html: message.content }} />\n",
    "                )}\n",
    "              </div>\n",
    "              {message.role === \"user\" && index === 0 && isFirstQuery && (\n",
    "                <div className={styles.chartContainer}>\n",
    "                  <StockChart data={stockData} />\n",
    "                </div>\n",
    "              )}\n",
    "              {message.subgraphResults && (\n",
    "                <div className={styles.subgraphMessage}>\n",
    "                  <SubgraphResults results={message.subgraphResults} />\n",
    "                </div>\n",
    "              )}\n",
    "            </React.Fragment>\n",
    "          ))}\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define your functions\n",
    "def vector_db_search(query: str) -> str:\n",
    "    # Implement your vector database search here\n",
    "    return f\"Vector DB result for: {query}\"\n",
    "\n",
    "def query_expansion(query: str) -> List[str]:\n",
    "    # Implement your query expansion logic here\n",
    "    return [f\"{query} expanded 1\", f\"{query} expanded 2\"]\n",
    "\n",
    "def api_call(query: str) -> str:\n",
    "    # Implement your API call here\n",
    "    return f\"API result for: {query}\"\n",
    "\n",
    "# Define the routing logic\n",
    "def route_query(state):\n",
    "    query = state['query']\n",
    "    if len(query.split()) > 3:  # Simple routing logic, adjust as needed\n",
    "        return \"query_expansion\"\n",
    "    else:\n",
    "        return \"vector_db_search\"\n",
    "\n",
    "# Define the query expansion and API call logic\n",
    "def expand_and_call(state):\n",
    "    expanded_queries = query_expansion(state['query'])\n",
    "    results = []\n",
    "    for eq in expanded_queries:\n",
    "        results.append(api_call(eq))\n",
    "    return {\"expanded_results\": results}\n",
    "\n",
    "# Define the aggregation logic\n",
    "def aggregate_results(state):\n",
    "    if \"expanded_results\" in state:\n",
    "        # Aggregate expanded results\n",
    "        combined = \" \".join(state[\"expanded_results\"])\n",
    "        return {\"response\": f\"Aggregated results: {combined}\"}\n",
    "    else:\n",
    "        # Return vector DB result\n",
    "        return {\"response\": state[\"result\"]}\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(name=\"QueryProcessor\")\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"route\", route_query)\n",
    "workflow.add_node(\"vector_db_search\", lambda state: {\"result\": vector_db_search(state['query'])})\n",
    "workflow.add_node(\"expand_and_call\", expand_and_call)\n",
    "workflow.add_node(\"aggregate\", aggregate_results)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"route\", \"vector_db_search\")\n",
    "workflow.add_edge(\"route\", \"expand_and_call\")\n",
    "workflow.add_edge(\"vector_db_search\", \"aggregate\")\n",
    "workflow.add_edge(\"expand_and_call\", \"aggregate\")\n",
    "workflow.add_edge(\"aggregate\", END)\n",
    "\n",
    "# Set the entrypoint\n",
    "workflow.set_entry_point(\"route\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the capital of France?\"\n",
    "result = app.invoke({\"query\": query})\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Check if CUDA is available, otherwise fallback to CPU (GPU is prioritized)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up the original training data (noisy sine wave) and move to GPU\n",
    "train_x_full = torch.linspace(0, 1, 100).cuda()  # 100 data points\n",
    "train_y_full = (torch.sin(train_x_full * (2 * math.pi)) + \n",
    "                torch.randn(train_x_full.size()).cuda() * math.sqrt(0.04))\n",
    "\n",
    "# Define the GP Model (with device support)\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean().cuda()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel().cuda()).cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Initialize likelihood and move it to GPU\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().cuda()\n",
    "\n",
    "# Incrementally add data and retrain the model before predicting the next day\n",
    "results = []\n",
    "\n",
    "initial_train_size = 10  # Start with 10 initial points\n",
    "for day in range(initial_train_size, len(train_x_full)):\n",
    "    # Add one more data point to the training set\n",
    "    train_x = train_x_full[:day]\n",
    "    train_y = train_y_full[:day]\n",
    "    test_x = train_x_full[day].unsqueeze(0)  # The next data point to predict\n",
    "\n",
    "    # Define the GP model with the updated training set and move to GPU\n",
    "    model = ExactGPModel(train_x, train_y, likelihood).cuda()\n",
    "\n",
    "    # Set training mode\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # Use the Adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    # Training loop\n",
    "    training_iter = 50\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Switch to evaluation mode after training\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Predict on the next day (test_x)\n",
    "    with torch.no_grad():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Collect the prediction and actual result\n",
    "    pred_mean = observed_pred.mean.cpu().numpy()  # Move prediction to CPU for plotting\n",
    "    test_actual = train_y_full[day].cpu().numpy()  # Actual value for comparison\n",
    "\n",
    "    results.append({\n",
    "        \"day\": day,\n",
    "        \"test_actual\": test_actual,\n",
    "        \"pred_mean\": pred_mean\n",
    "    })\n",
    "\n",
    "# Visualize the results\n",
    "days = [result[\"day\"] for result in results]\n",
    "test_actuals = [result[\"test_actual\"] for result in results]\n",
    "pred_means = [result[\"pred_mean\"] for result in results]\n",
    "\n",
    "plt.plot(days, test_actuals, 'k*', label=\"Actual\")\n",
    "plt.plot(days, pred_means, 'b', label=\"Predicted Mean\")\n",
    "plt.fill_between(\n",
    "    days, \n",
    "    [result[\"pred_mean\"] - 2*math.sqrt(0.04) for result in results], \n",
    "    [result[\"pred_mean\"] + 2*math.sqrt(0.04) for result in results], \n",
    "    color='blue', alpha=0.5\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Incremental GP Predictions with Daily Data Addition (Cross-Validation)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
