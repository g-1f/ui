{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2490503976.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    import React from 'react';\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import React from 'react';\n",
    "import Highcharts from 'highcharts/highstock';\n",
    "import HighchartsReact from 'highcharts-react-official';\n",
    "\n",
    "const StockChart = ({ data }) => {\n",
    "  const options = {\n",
    "    title: {\n",
    "      text: 'Stock Price'\n",
    "    },\n",
    "    xAxis: {\n",
    "      type: 'datetime'\n",
    "    },\n",
    "    yAxis: {\n",
    "      title: {\n",
    "        text: 'Price'\n",
    "      }\n",
    "    },\n",
    "    series: [{\n",
    "      name: 'Stock Price',\n",
    "      data: data,\n",
    "      tooltip: {\n",
    "        valueDecimals: 2\n",
    "      }\n",
    "    }]\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <HighchartsReact\n",
    "      highcharts={Highcharts}\n",
    "      constructorType={'stockChart'}\n",
    "      options={options}\n",
    "    />\n",
    "  );\n",
    "};\n",
    "\n",
    "export default StockChart;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " if (isChatActive) {\n",
    "    return (\n",
    "      <div className={styles.chatPage}>\n",
    "        <div className={styles.chatHeader}>\n",
    "          <div className={styles.chatHeaderTitle}>\n",
    "            <div className={styles.iconWrapper}>\n",
    "              <FluentIcons.Sparkle24Filled />\n",
    "            </div>\n",
    "            <Text className={styles.chatHeaderText}>{userConfig.buttons[0].label}</Text>\n",
    "          </div>\n",
    "          <Text className={styles.chatHeaderDescription}>{userConfig.buttons[0].description}</Text>\n",
    "        </div>\n",
    "        <div className={styles.chatMessages}>\n",
    "          {chatMessages.map((message, index) => (\n",
    "            <React.Fragment key={index}>\n",
    "              <div\n",
    "                className={`${styles.chatMessage} ${\n",
    "                  message.role === \"user\" ? styles.userMessage : styles.assistantMessage\n",
    "                }`}\n",
    "              >\n",
    "                {message.role === \"user\" ? (\n",
    "                  message.content\n",
    "                ) : (\n",
    "                  <div dangerouslySetInnerHTML={{ __html: message.content }} />\n",
    "                )}\n",
    "              </div>\n",
    "              {message.role === \"user\" && index === 0 && isFirstQuery && (\n",
    "                <div className={styles.chartContainer}>\n",
    "                  <StockChart data={stockData} />\n",
    "                </div>\n",
    "              )}\n",
    "              {message.subgraphResults && (\n",
    "                <div className={styles.subgraphMessage}>\n",
    "                  <SubgraphResults results={message.subgraphResults} />\n",
    "                </div>\n",
    "              )}\n",
    "            </React.Fragment>\n",
    "          ))}\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define your functions\n",
    "def vector_db_search(query: str) -> str:\n",
    "    # Implement your vector database search here\n",
    "    return f\"Vector DB result for: {query}\"\n",
    "\n",
    "def query_expansion(query: str) -> List[str]:\n",
    "    # Implement your query expansion logic here\n",
    "    return [f\"{query} expanded 1\", f\"{query} expanded 2\"]\n",
    "\n",
    "def api_call(query: str) -> str:\n",
    "    # Implement your API call here\n",
    "    return f\"API result for: {query}\"\n",
    "\n",
    "# Define the routing logic\n",
    "def route_query(state):\n",
    "    query = state['query']\n",
    "    if len(query.split()) > 3:  # Simple routing logic, adjust as needed\n",
    "        return \"query_expansion\"\n",
    "    else:\n",
    "        return \"vector_db_search\"\n",
    "\n",
    "# Define the query expansion and API call logic\n",
    "def expand_and_call(state):\n",
    "    expanded_queries = query_expansion(state['query'])\n",
    "    results = []\n",
    "    for eq in expanded_queries:\n",
    "        results.append(api_call(eq))\n",
    "    return {\"expanded_results\": results}\n",
    "\n",
    "# Define the aggregation logic\n",
    "def aggregate_results(state):\n",
    "    if \"expanded_results\" in state:\n",
    "        # Aggregate expanded results\n",
    "        combined = \" \".join(state[\"expanded_results\"])\n",
    "        return {\"response\": f\"Aggregated results: {combined}\"}\n",
    "    else:\n",
    "        # Return vector DB result\n",
    "        return {\"response\": state[\"result\"]}\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(name=\"QueryProcessor\")\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"route\", route_query)\n",
    "workflow.add_node(\"vector_db_search\", lambda state: {\"result\": vector_db_search(state['query'])})\n",
    "workflow.add_node(\"expand_and_call\", expand_and_call)\n",
    "workflow.add_node(\"aggregate\", aggregate_results)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"route\", \"vector_db_search\")\n",
    "workflow.add_edge(\"route\", \"expand_and_call\")\n",
    "workflow.add_edge(\"vector_db_search\", \"aggregate\")\n",
    "workflow.add_edge(\"expand_and_call\", \"aggregate\")\n",
    "workflow.add_edge(\"aggregate\", END)\n",
    "\n",
    "# Set the entrypoint\n",
    "workflow.set_entry_point(\"route\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the capital of France?\"\n",
    "result = app.invoke({\"query\": query})\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up the training data (noisy sine wave)\n",
    "train_x_full = torch.linspace(0, 1, 100).to(device)\n",
    "train_y_full = torch.sin(train_x_full * (2 * math.pi)) + torch.randn(train_x_full.size()).to(device) * math.sqrt(0.04)\n",
    "\n",
    "# Define the GP Model\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean().to(device)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel().to(device)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def train_and_evaluate_loocv():\n",
    "    n_points = len(train_x_full)\n",
    "    results = []\n",
    "    mse_loss_list = []\n",
    "    hyperparameter_history = []\n",
    "    \n",
    "    # Perform LOOCV\n",
    "    for left_out_idx in tqdm(range(n_points), desc=\"LOOCV Progress\"):\n",
    "        # Create training set without the left-out point\n",
    "        mask = torch.ones(n_points, dtype=bool)\n",
    "        mask[left_out_idx] = False\n",
    "        \n",
    "        train_x = train_x_full[mask].reshape(-1, 1)\n",
    "        train_y = train_y_full[mask]\n",
    "        test_x = train_x_full[left_out_idx].reshape(1, 1)\n",
    "        test_y = train_y_full[left_out_idx]\n",
    "        \n",
    "        # Initialize model and likelihood\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "        model = ExactGPModel(train_x, train_y, likelihood).to(device)\n",
    "        \n",
    "        # Training mode\n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        \n",
    "        # Optimize hyperparameters\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(50):  # 50 training iterations\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Store hyperparameters\n",
    "        hyperparameters = {\n",
    "            'lengthscale': model.covar_module.base_kernel.lengthscale.item(),\n",
    "            'outputscale': model.covar_module.outputscale.item(),\n",
    "            'noise': model.likelihood.noise.item()\n",
    "        }\n",
    "        hyperparameter_history.append(hyperparameters)\n",
    "        \n",
    "        # Evaluation mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            observed_pred = likelihood(model(test_x))\n",
    "            pred_mean = observed_pred.mean.cpu().numpy().item()\n",
    "            pred_std = torch.sqrt(observed_pred.variance).cpu().numpy().item()\n",
    "        \n",
    "        # Calculate MSE for this point\n",
    "        test_actual = test_y.cpu().numpy().item()\n",
    "        mse_loss = (pred_mean - test_actual) ** 2\n",
    "        mse_loss_list.append(mse_loss)\n",
    "        \n",
    "        results.append({\n",
    "            'index': left_out_idx,\n",
    "            'x': test_x.cpu().numpy().item(),\n",
    "            'actual': test_actual,\n",
    "            'predicted': pred_mean,\n",
    "            'std': pred_std,\n",
    "            'mse': mse_loss,\n",
    "            'hyperparameters': hyperparameters\n",
    "        })\n",
    "        \n",
    "        if left_out_idx % 10 == 0:\n",
    "            print(f\"\\nPoint {left_out_idx}:\")\n",
    "            print(f\"MSE: {mse_loss:.4f}\")\n",
    "            print(f\"Hyperparameters: {hyperparameters}\")\n",
    "    \n",
    "    return results, mse_loss_list, hyperparameter_history\n",
    "\n",
    "# Run LOOCV\n",
    "results, mse_loss_list, hyperparameter_history = train_and_evaluate_loocv()\n",
    "\n",
    "# Sort results by x-value for plotting\n",
    "sorted_results = sorted(results, key=lambda x: x['x'])\n",
    "x_values = [r['x'] for r in sorted_results]\n",
    "actual_values = [r['actual'] for r in sorted_results]\n",
    "predicted_values = [r['predicted'] for r in sorted_results]\n",
    "std_values = [r['std'] for r in sorted_results]\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Prediction plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_values, actual_values, 'k*', label='Actual', markersize=4)\n",
    "plt.plot(x_values, predicted_values, 'b-', label='Predicted')\n",
    "plt.fill_between(\n",
    "    x_values,\n",
    "    [p - 2*s for p, s in zip(predicted_values, std_values)],\n",
    "    [p + 2*s for p, s in zip(predicted_values, std_values)],\n",
    "    color='blue', alpha=0.2, label='95% Confidence'\n",
    ")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('LOOCV Predictions vs Actual Values')\n",
    "plt.legend()\n",
    "\n",
    "# MSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_values, mse_loss_list, 'r-', label='MSE')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'MSE at Each Point (Mean: {np.mean(mse_loss_list):.4f})')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot hyperparameter evolution\n",
    "plt.figure(figsize=(12, 4))\n",
    "hp_x = range(len(hyperparameter_history))\n",
    "plt.plot(hp_x, [h['lengthscale'] for h in hyperparameter_history], label='Lengthscale')\n",
    "plt.plot(hp_x, [h['outputscale'] for h in hyperparameter_history], label='Outputscale')\n",
    "plt.plot(hp_x, [h['noise'] for h in hyperparameter_history], label='Noise')\n",
    "plt.xlabel('Point Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Hyperparameter Evolution During LOOCV')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set up the training data (noisy sine wave)\n",
    "train_x_full = torch.linspace(0, 1, 100).to(device)\n",
    "train_y_full = torch.sin(train_x_full * (2 * math.pi)) + torch.randn(train_x_full.size()).to(device) * math.sqrt(0.04)\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean().to(device)\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel().to(device)\n",
    "        ).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "def get_looph_predictions():\n",
    "    \"\"\"Get LOO predictions using LOOPH with fixed parameters\"\"\"\n",
    "    # Initialize model with fixed parameters\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "    model = ExactGPModel(train_x_full, train_y_full, likelihood).to(device)\n",
    "    \n",
    "    # Set fixed parameters\n",
    "    model.covar_module.base_kernel.lengthscale = 0.2\n",
    "    model.covar_module.outputscale = 1.0\n",
    "    likelihood.noise = 0.04\n",
    "    \n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    \n",
    "    # Use LOOPH to get predictions\n",
    "    with torch.no_grad():\n",
    "        output = model(train_x_full)\n",
    "        # Compute the full covariance matrix\n",
    "        f_covar = output.covariance_matrix\n",
    "        f_mean = output.mean\n",
    "        \n",
    "        # Get LOO predictions using the equations from RW 5.4.2\n",
    "        S = f_covar + likelihood.noise * torch.eye(f_covar.shape[0]).to(device)\n",
    "        S_inv = torch.linalg.inv(S)\n",
    "        \n",
    "        # Compute LOO means and variances\n",
    "        S_inv_diag = S_inv.diag()\n",
    "        loo_means = f_mean - (S_inv @ train_y_full) / S_inv_diag\n",
    "        loo_vars = 1.0 / S_inv_diag\n",
    "        \n",
    "        # Compute negative log predictive probability\n",
    "        nlpp = 0.5 * torch.log(2 * math.pi * loo_vars) + \\\n",
    "               0.5 * (train_y_full - loo_means).pow(2) / loo_vars\n",
    "        \n",
    "    return {\n",
    "        'means': loo_means,\n",
    "        'vars': loo_vars,\n",
    "        'nlpp': nlpp.sum().item(),\n",
    "        'nlpp_per_point': nlpp\n",
    "    }\n",
    "\n",
    "def get_loocv_predictions():\n",
    "    \"\"\"Get predictions using traditional LOOCV with fixed parameters\"\"\"\n",
    "    n_points = len(train_x_full)\n",
    "    predictions = []\n",
    "    nlpp_values = []\n",
    "    \n",
    "    for left_out_idx in tqdm(range(n_points), desc=\"LOOCV Progress\"):\n",
    "        # Create training set without the left-out point\n",
    "        mask = torch.ones(n_points, dtype=bool)\n",
    "        mask[left_out_idx] = False\n",
    "        \n",
    "        train_x = train_x_full[mask].reshape(-1, 1)\n",
    "        train_y = train_y_full[mask]\n",
    "        test_x = train_x_full[left_out_idx].reshape(1, 1)\n",
    "        test_y = train_y_full[left_out_idx]\n",
    "        \n",
    "        # Initialize model with fixed parameters\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "        model = ExactGPModel(train_x, train_y, likelihood).to(device)\n",
    "        \n",
    "        # Set fixed parameters\n",
    "        model.covar_module.base_kernel.lengthscale = 0.2\n",
    "        model.covar_module.outputscale = 1.0\n",
    "        likelihood.noise = 0.04\n",
    "        \n",
    "        # Evaluation mode\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            observed_pred = likelihood(model(test_x))\n",
    "            pred_mean = observed_pred.mean\n",
    "            pred_var = observed_pred.variance\n",
    "            \n",
    "            # Compute NLPP for this point\n",
    "            nlpp = 0.5 * torch.log(2 * math.pi * pred_var) + \\\n",
    "                   0.5 * (test_y - pred_mean).pow(2) / pred_var\n",
    "            \n",
    "        predictions.append({\n",
    "            'mean': pred_mean.cpu().item(),\n",
    "            'variance': pred_var.cpu().item()\n",
    "        })\n",
    "        nlpp_values.append(nlpp.cpu().item())\n",
    "    \n",
    "    # Organize results\n",
    "    means = np.array([p['mean'] for p in predictions])\n",
    "    vars = np.array([p['variance'] for p in predictions])\n",
    "    \n",
    "    return {\n",
    "        'means': means,\n",
    "        'vars': vars,\n",
    "        'nlpp': sum(nlpp_values),\n",
    "        'nlpp_per_point': np.array(nlpp_values)\n",
    "    }\n",
    "\n",
    "# Get predictions from both methods\n",
    "print(\"Computing LOOPH predictions...\")\n",
    "looph_results = get_looph_predictions()\n",
    "\n",
    "print(\"Computing LOOCV predictions...\")\n",
    "loocv_results = get_loocv_predictions()\n",
    "\n",
    "# Convert results to numpy for plotting\n",
    "x_values = train_x_full.cpu().numpy()\n",
    "actual_values = train_y_full.cpu().numpy()\n",
    "looph_means = looph_results['means'].cpu().numpy()\n",
    "looph_stds = np.sqrt(looph_results['vars'].cpu().numpy())\n",
    "loocv_means = loocv_results['means']\n",
    "loocv_stds = np.sqrt(loocv_results['vars'])\n",
    "\n",
    "# Create comparison plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Predictions comparison\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x_values, actual_values, 'k*', label='Actual', markersize=4)\n",
    "plt.plot(x_values, looph_means, 'b-', label='LOOPH Predictions')\n",
    "plt.fill_between(x_values, \n",
    "                 looph_means - 2*looph_stds,\n",
    "                 looph_means + 2*looph_stds,\n",
    "                 color='blue', alpha=0.2, label='LOOPH 95% CI')\n",
    "plt.plot(x_values, loocv_means, 'r--', label='LOOCV Predictions')\n",
    "plt.fill_between(x_values,\n",
    "                 loocv_means - 2*loocv_stds,\n",
    "                 loocv_means + 2*loocv_stds,\n",
    "                 color='red', alpha=0.2, label='LOOCV 95% CI')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Predictions Comparison: LOOPH vs LOOCV')\n",
    "plt.legend()\n",
    "\n",
    "# NLPP comparison\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x_values, looph_results['nlpp_per_point'].cpu().numpy(), 'b-', label='LOOPH NLPP')\n",
    "plt.plot(x_values, loocv_results['nlpp_per_point'], 'r--', label='LOOCV NLPP')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('NLPP')\n",
    "plt.title('Negative Log Predictive Probability Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute and print metrics\n",
    "rmse_looph = np.sqrt(np.mean((looph_means - actual_values) ** 2))\n",
    "rmse_loocv = np.sqrt(np.mean((loocv_means - actual_values) ** 2))\n",
    "\n",
    "print(\"\\nPerformance Metrics:\")\n",
    "print(f\"LOOPH RMSE: {rmse_looph:.4f}\")\n",
    "print(f\"LOOCV RMSE: {rmse_loocv:.4f}\")\n",
    "print(f\"LOOPH Total NLPP: {looph_results['nlpp']:.4f}\")\n",
    "print(f\"LOOCV Total NLPP: {loocv_results['nlpp']:.4f}\")\n",
    "\n",
    "# Compute correlation between predictions\n",
    "correlation = np.corrcoef(looph_means, loocv_means)[0,1]\n",
    "print(f\"\\nCorrelation between LOOPH and LOOCV predictions: {correlation:.4f}\")\n",
    "\n",
    "# Plot prediction differences\n",
    "plt.figure(figsize=(10, 5))\n",
    "prediction_diff = looph_means - loocv_means\n",
    "plt.plot(x_values, prediction_diff, 'g-', label='LOOPH - LOOCV')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Prediction Difference')\n",
    "plt.title('Difference between LOOPH and LOOCV Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
