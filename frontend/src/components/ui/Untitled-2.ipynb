{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.schema.runnable'; 'langchain.schema' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, Any, List, TypedDict\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough, RunnableLambda, RunnableParallel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate, ChatPromptTemplate\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.schema.runnable'; 'langchain.schema' is not a package"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import Graph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Dict, Any\n",
    "import asyncio\n",
    "from neo4j import AsyncGraphDatabase\n",
    "import logging\n",
    "\n",
    "# Assume llm is imported and configured\n",
    "from your_llm_config import llm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AgentState(Dict):\n",
    "    query: str\n",
    "    use_graph_db: bool\n",
    "    graph_db_result: Dict[str, Any]\n",
    "\n",
    "async def graph_db_router(state: AgentState) -> AgentState:\n",
    "    logger.debug(f\"Entering graph_db_router with query: {state['query']}\")\n",
    "    \n",
    "    router_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"Analyze the following query and determine if it can utilize graph relationships:\n",
    "        \n",
    "        Query: {query}\n",
    "        \n",
    "        Respond with either 'Yes' or 'No' followed by a brief explanation.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    result = await router_prompt.aformat(query=state[\"query\"]) | llm | str\n",
    "    state[\"use_graph_db\"] = result.lower().startswith(\"yes\")\n",
    "    \n",
    "    logger.debug(f\"graph_db_router decision: use_graph_db = {state['use_graph_db']}\")\n",
    "    logger.debug(f\"LLM explanation: {result}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "async def query_graph_db(state: AgentState) -> AgentState:\n",
    "    logger.debug(f\"Entering query_graph_db with use_graph_db: {state['use_graph_db']}\")\n",
    "    \n",
    "    if not state[\"use_graph_db\"]:\n",
    "        logger.debug(\"Skipping graph DB query as use_graph_db is False\")\n",
    "        return state\n",
    "\n",
    "    # Replace with your actual Neo4j connection details\n",
    "    uri = \"neo4j://localhost:7687\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"password\"\n",
    "\n",
    "    try:\n",
    "        async with AsyncGraphDatabase.driver(uri, auth=(user, password)) as driver:\n",
    "            async with driver.session() as session:\n",
    "                # This is a placeholder Cypher query. Replace with actual query generation logic.\n",
    "                cypher_query = f\"MATCH (n) WHERE n.name CONTAINS '{state['query']}' RETURN n LIMIT 5\"\n",
    "                logger.debug(f\"Executing Cypher query: {cypher_query}\")\n",
    "                \n",
    "                result = await session.run(cypher_query)\n",
    "                state[\"graph_db_result\"] = [record.data() for record in await result.data()]\n",
    "                \n",
    "                logger.debug(f\"Graph DB query result: {state['graph_db_result']}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error querying graph database: {str(e)}\")\n",
    "        state[\"graph_db_result\"] = {\"error\": str(e)}\n",
    "\n",
    "    return state\n",
    "\n",
    "def create_debug_graph():\n",
    "    workflow = Graph()\n",
    "\n",
    "    workflow.add_node(\"graph_db_router\", RunnableLambda(graph_db_router))\n",
    "    workflow.add_node(\"query_graph_db\", RunnableLambda(query_graph_db))\n",
    "\n",
    "    workflow.add_edge(\"graph_db_router\", \"query_graph_db\")\n",
    "    workflow.add_edge(\"query_graph_db\", END)\n",
    "\n",
    "    workflow.set_entry_point(\"graph_db_router\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "async def run_debug_graph(query: str):\n",
    "    graph = create_debug_graph()\n",
    "    initial_state = AgentState(\n",
    "        query=query,\n",
    "        use_graph_db=False,\n",
    "        graph_db_result={}\n",
    "    )\n",
    "    result = await graph.ainvoke(initial_state)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    async def main():\n",
    "        queries = [\n",
    "            \"What were Apple's financial highlights in the last quarter?\",\n",
    "            \"List all companies in the tech sector\",\n",
    "            \"What is the current stock price of Google?\"\n",
    "        ]\n",
    "        \n",
    "        for query in queries:\n",
    "            logger.info(f\"\\nProcessing query: {query}\")\n",
    "            result = await run_debug_graph(query)\n",
    "            logger.info(f\"Final state for query '{query}':\")\n",
    "            logger.info(f\"use_graph_db: {result['use_graph_db']}\")\n",
    "            logger.info(f\"graph_db_result: {result['graph_db_result']}\")\n",
    "            logger.info(\"-\" * 50)\n",
    "\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
