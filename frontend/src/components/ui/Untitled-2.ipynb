{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    query: str\n",
    "    results: Dict[str, str]\n",
    "    next_steps: List[str]\n",
    "\n",
    "# Node functions\n",
    "def node_a(state: GraphState) -> Dict[str, Any]:\n",
    "    print(\"Executing node_a\")\n",
    "    # Decide which nodes to execute next\n",
    "    return {\"next_steps\": [\"b\", \"c\", \"d\"]}\n",
    "\n",
    "async def search_and_generate(node: str, state: GraphState, prompt: PromptTemplate) -> Dict[str, str]:\n",
    "    print(f\"Executing {node}\")\n",
    "    # Perform search\n",
    "    search_results = await run_vespa_search(state[\"query\"], top_k=5, tags=node)\n",
    "    \n",
    "    # Generate response with LLM\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"query\": state[\"query\"], \"search_results\": search_results})\n",
    "    return {node: response}\n",
    "\n",
    "def create_node_function(node: str, prompt: PromptTemplate):\n",
    "    def node_function(state: GraphState) -> Dict[str, Any]:\n",
    "        result = asyncio.run(search_and_generate(node, state, prompt))\n",
    "        return {\"results\": {node: result[node]}}\n",
    "    return node_function\n",
    "\n",
    "# Define prompts for each node\n",
    "prompt_b = PromptTemplate.from_template(\n",
    "    \"Analyze the following search results for the query: {query}\\n\\nSearch Results: {search_results}\\n\\nProvide a concise summary focusing on the main points.\"\n",
    ")\n",
    "\n",
    "prompt_c = PromptTemplate.from_template(\n",
    "    \"Given the query: {query}\\n\\nAnd the search results: {search_results}\\n\\nIdentify any conflicting information or controversies in the results.\"\n",
    ")\n",
    "\n",
    "prompt_d = PromptTemplate.from_template(\n",
    "    \"For the query: {query}\\n\\nBased on these search results: {search_results}\\n\\nProvide potential future developments or implications.\"\n",
    ")\n",
    "\n",
    "# Create node functions\n",
    "node_b = create_node_function(\"b\", prompt_b)\n",
    "node_c = create_node_function(\"c\", prompt_c)\n",
    "node_d = create_node_function(\"d\", prompt_d)\n",
    "\n",
    "def aggregate_results(state: GraphState) -> Dict[str, Any]:\n",
    "    print(\"Aggregating results\")\n",
    "    combined_response = \"\\n\".join([f\"Node {k}: {v}\" for k, v in state[\"results\"].items()])\n",
    "    \n",
    "    aggregate_prompt = PromptTemplate.from_template(\n",
    "        \"Synthesize a comprehensive answer based on these results:\\n{combined_response}\\n\\nProvide a well-structured and coherent response that addresses the original query: {query}\"\n",
    "    )\n",
    "    \n",
    "    chain = aggregate_prompt | llm\n",
    "    final_result = chain.invoke({\"combined_response\": combined_response, \"query\": state[\"query\"]})\n",
    "    return {\"final_result\": final_result}\n",
    "\n",
    "# Router function\n",
    "def router(state: GraphState) -> List[str]:\n",
    "    return state[\"next_steps\"]\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"a\", node_a)\n",
    "workflow.add_node(\"b\", node_b)\n",
    "workflow.add_node(\"c\", node_c)\n",
    "workflow.add_node(\"d\", node_d)\n",
    "workflow.add_node(\"aggregate\", aggregate_results)\n",
    "\n",
    "# Add edges with conditional routing\n",
    "workflow.add_conditional_edges(\n",
    "    \"a\",\n",
    "    router,\n",
    "    {\n",
    "        \"b\": \"b\",\n",
    "        \"c\": \"c\",\n",
    "        \"d\": \"d\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"b\", \"aggregate\")\n",
    "workflow.add_edge(\"c\", \"aggregate\")\n",
    "workflow.add_edge(\"d\", \"aggregate\")\n",
    "workflow.add_edge(\"aggregate\", END)\n",
    "\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"a\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Run the graph\n",
    "query = \"What are the latest advancements in quantum computing?\"\n",
    "initial_state = {\"query\": query, \"results\": {}, \"next_steps\": []}\n",
    "result = graph.invoke(initial_state)\n",
    "print(f\"Final result: {result['final_result']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
