{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def finance_agent_generator(query: str):\n",
    "    graph = create_finance_agent_graph()\n",
    "    initial_state = AgentState(\n",
    "        query=query,\n",
    "        processed_query=\"\",\n",
    "        use_graph_db=False,\n",
    "        graph_db_result=[],\n",
    "        expanded_queries=[],\n",
    "        subgraphs_to_execute=3,\n",
    "        subgraph_results={},\n",
    "        final_response=\"\"\n",
    "    )\n",
    "    current_state = initial_state\n",
    "    \n",
    "    last_node = None\n",
    "    async for chunk in graph.astream(current_state, stream_mode=\"updates\"):\n",
    "        for node, node_state in chunk.items():\n",
    "            if isinstance(node_state, dict):\n",
    "                yield f\"data: {json.dumps({'type': 'step', 'content': node})}\\n\\n\"\n",
    "                last_node = node\n",
    "            else:\n",
    "                print(f\"Unexpected state type for node {node}: {type(node_state)}.\")\n",
    "        \n",
    "        # After processing all nodes, check if we have a final response\n",
    "        if last_node and 'final_response' in chunk[last_node]:\n",
    "            final_response = chunk[last_node]['final_response']\n",
    "            if final_response:\n",
    "                yield f\"data: {json.dumps({'type': 'final', 'content': final_response})}\\n\\n\"\n",
    "\n",
    "    yield \"data: [DONE]\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  const handleAction = useCallback(async (userInput) => {\n",
    "    setIsProcessing(true);\n",
    "    setError(null);\n",
    "    setStatusMessage(null);\n",
    "    setProcessingSteps([]);\n",
    "    \n",
    "    setChatMessages(prevMessages => [...prevMessages, { role: \"user\", content: userInput }]);\n",
    "    \n",
    "    try {\n",
    "      const content = await getEmailContent();\n",
    "      const payload = {\n",
    "        userId: userConfig.userId,\n",
    "        emailContent: content,\n",
    "        prompt: userInput,\n",
    "      };\n",
    "\n",
    "      const response = await fetch(\"http://localhost:8001/fluent_ai\", {\n",
    "        method: \"POST\",\n",
    "        headers: { \"Content-Type\": \"application/json\" },\n",
    "        body: JSON.stringify(payload),\n",
    "      });\n",
    "\n",
    "      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);\n",
    "      \n",
    "      const reader = response.body.getReader();\n",
    "      const decoder = new TextDecoder();\n",
    "\n",
    "      let buffer = '';\n",
    "      while (true) {\n",
    "        const { value, done } = await reader.read();\n",
    "        if (done) break;\n",
    "        \n",
    "        buffer += decoder.decode(value, { stream: true });\n",
    "        const lines = buffer.split('\\n');\n",
    "        buffer = lines.pop();\n",
    "\n",
    "        for (const line of lines) {\n",
    "          if (line.startsWith('data: ')) {\n",
    "            try {\n",
    "              const data = JSON.parse(line.slice(5));\n",
    "              if (data === '[DONE]') {\n",
    "                setIsProcessing(false);\n",
    "              } else {\n",
    "                handleUpdate(data);\n",
    "              }\n",
    "            } catch (error) {\n",
    "              console.error('Error parsing SSE data:', error);\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    } catch (e) {\n",
    "      console.error(`Error in handleAction: ${e.message}`);\n",
    "      setError('Failed to process your request. Please try again.');\n",
    "      setIsProcessing(false);\n",
    "    }\n",
    "  }, [userConfig, getEmailContent]);\n",
    "\n",
    "  const handleUpdate = useCallback((data) => {\n",
    "    if (data.type === 'step') {\n",
    "      setProcessingSteps(prevSteps => [...prevSteps, data.content]);\n",
    "    } else if (data.type === 'final') {\n",
    "      setChatMessages(prevMessages => [\n",
    "        ...prevMessages,\n",
    "        { role: \"assistant\", content: wrapInHtml(data.content) }\n",
    "      ]);\n",
    "      setIsProcessing(false);\n",
    "    }\n",
    "  }, []);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
